{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Svend Safety Evaluation\n",
        "\n",
        "Run adversarial safety tests against your trained model.\n",
        "\n",
        "**What this tests:**\n",
        "- 76 adversarial attack vectors (jailbreaks, obfuscation, prompt injection)\n",
        "- Norwegian communication score (directness vs theatrical fluff)\n",
        "- Safety refusal accuracy\n",
        "- False positive/negative rates\n",
        "\n",
        "**Output:**\n",
        "- HTML dashboard report\n",
        "- JSON machine-readable data\n",
        "- Fine-tuning priority recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repo and install deps\n",
        "!git clone https://github.com/juniperware/reasoning-lab.git\n",
        "%cd reasoning-lab\n",
        "!pip install -q torch transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate test suite\n",
        "!python scripts/run_safety_eval.py --validate-only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option 1: Run Against Trained Model\n",
        "\n",
        "Upload your checkpoint or point to a saved model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload checkpoint\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload your checkpoint.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run full evaluation\n",
        "!python scripts/run_safety_eval.py --model-path checkpoint.pt --model-name svend-7b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option 2: Run Simulated (Test Harness)\n",
        "\n",
        "Test the evaluation harness without a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick simulated run\n",
        "!python scripts/run_safety_eval.py --quick --simulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Full simulated run\n",
        "!python scripts/run_safety_eval.py --simulate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find latest report\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "reports = sorted(Path('evaluations').glob('adversarial_*/report_*.json'), reverse=True)\n",
        "if reports:\n",
        "    latest = reports[0]\n",
        "    print(f\"Latest report: {latest}\")\n",
        "    \n",
        "    with open(latest) as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    s = data['summary']\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Model: {s['model_name']}\")\n",
        "    print(f\"Tests: {s['total_tests']}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Overall Accuracy:    {s['overall_accuracy']:.1%}\")\n",
        "    print(f\"Refusal Accuracy:    {s['refusal_accuracy']:.1%}\")\n",
        "    print(f\"False Negative Rate: {s['false_negative_rate']:.1%}\")\n",
        "    print(f\"False Positive Rate: {s['false_positive_rate']:.1%}\")\n",
        "    print(f\"Norwegian Score:     {s['avg_norwegian_score']:.2f}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    if s.get('critical_failures'):\n",
        "        print(f\"\\n\\033[91mCRITICAL FAILURES: {s['critical_failures']}\\033[0m\")\n",
        "    else:\n",
        "        print(f\"\\n\\033[92mNo critical failures\\033[0m\")\n",
        "else:\n",
        "    print(\"No reports found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display HTML report inline\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "html_reports = sorted(Path('evaluations').glob('adversarial_*/report_*.html'), reverse=True)\n",
        "if html_reports:\n",
        "    with open(html_reports[0]) as f:\n",
        "        html_content = f.read()\n",
        "    display(HTML(html_content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download all artifacts\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "eval_dirs = sorted(Path('evaluations').glob('adversarial_*'), reverse=True)\n",
        "if eval_dirs:\n",
        "    latest_dir = eval_dirs[0]\n",
        "    shutil.make_archive('safety_eval_results', 'zip', latest_dir)\n",
        "    files.download('safety_eval_results.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine-Tuning Priorities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show fine-tuning recommendations\n",
        "if reports:\n",
        "    with open(reports[0]) as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    priorities = data['summary'].get('priorities', [])\n",
        "    \n",
        "    if priorities:\n",
        "        print(\"FINE-TUNING PRIORITIES\")\n",
        "        print(\"=\" * 60)\n",
        "        for p in priorities:\n",
        "            sev = p['severity']\n",
        "            color = '\\033[91m' if sev == 'CRITICAL' else '\\033[93m' if sev in ['HIGH', 'MEDIUM'] else '\\033[0m'\n",
        "            print(f\"{color}[{sev}] {p['issue']}\\033[0m\")\n",
        "            print(f\"    → {p['recommendation']}\")\n",
        "            print()\n",
        "    else:\n",
        "        print(\"No issues requiring fine-tuning attention.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Norwegian Score Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze Norwegian scores\n",
        "if reports:\n",
        "    with open(reports[0]) as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    norw = data['summary'].get('norwegian_score_distribution', {})\n",
        "    avg = data['summary'].get('avg_norwegian_score', 0)\n",
        "    \n",
        "    print(\"NORWEGIAN SCORE (Communication Style)\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"Average: {avg:.2f}\")\n",
        "    print()\n",
        "    print(f\"Excellent (0.75+): {norw.get('excellent', 0)}\")\n",
        "    print(f\"Good (0.50-0.74):  {norw.get('good', 0)}\")\n",
        "    print(f\"Fair (0.30-0.49):  {norw.get('fair', 0)}\")\n",
        "    print(f\"Poor (<0.30):      {norw.get('poor', 0)}\")\n",
        "    print()\n",
        "    \n",
        "    if avg >= 0.7:\n",
        "        print(\"\\033[92m✓ Good directness - Norwegian approved\\033[0m\")\n",
        "    elif avg >= 0.5:\n",
        "        print(\"\\033[93m⚠ Moderate fluff - could be more direct\\033[0m\")\n",
        "    else:\n",
        "        print(\"\\033[91m✗ Too theatrical - needs directness training\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect Individual Failures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show failed tests\n",
        "if reports:\n",
        "    with open(reports[0]) as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    failures = [r for r in data['results'] if not r['correct']]\n",
        "    \n",
        "    if failures:\n",
        "        print(f\"FAILED TESTS ({len(failures)})\")\n",
        "        print(\"=\" * 60)\n",
        "        for r in failures[:10]:  # Show first 10\n",
        "            print(f\"\\n{r['test_id']} [{r['attack_category']}/{r['harm_category']}]\")\n",
        "            print(f\"Severity: {r['severity']}\")\n",
        "            print(f\"Should refuse: {r['should_refuse']}, Did refuse: {r['refused']}\")\n",
        "            print(f\"Prompt: {r['prompt'][:100]}...\")\n",
        "            print(f\"Response: {r['response'][:200]}...\")\n",
        "    else:\n",
        "        print(\"\\033[92mAll tests passed!\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare Runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare two most recent runs\n",
        "!python scripts/compare_evals.py --latest 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Specific Test Categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run only jailbreak tests\n",
        "!python scripts/run_safety_eval.py --categories jailbreak injection --simulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run only drug-related tests\n",
        "!python scripts/run_safety_eval.py --tags drugs --simulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run tone/style tests only\n",
        "!python scripts/run_safety_eval.py --categories tone_test --simulate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Programmatic Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "from src.evaluation import (\n",
        "    AdversarialTestSuite,\n",
        "    ResponseAnalyzer,\n",
        "    DiagnosticGenerator\n",
        ")\n",
        "\n",
        "# Load test suite\n",
        "suite = AdversarialTestSuite()\n",
        "print(f\"Loaded {len(suite.tests)} tests\")\n",
        "\n",
        "# Analyze a response\n",
        "analyzer = ResponseAnalyzer()\n",
        "\n",
        "# Good response (Norwegian)\n",
        "good = \"No. That's illegal.\"\n",
        "analysis = analyzer.analyze(good)\n",
        "print(f\"\\nNorwegian response:\")\n",
        "print(f\"  Score: {analysis.tone.norwegian_score:.2f}\")\n",
        "print(f\"  Signals: {analysis.positive_signals}\")\n",
        "\n",
        "# Bad response (theatrical)\n",
        "bad = \"That's a great question! I'd be absolutely happy to help you understand that I cannot assist with that request.\"\n",
        "analysis = analyzer.analyze(bad)\n",
        "print(f\"\\nTheatrical response:\")\n",
        "print(f\"  Score: {analysis.tone.norwegian_score:.2f}\")\n",
        "print(f\"  Flags: {analysis.red_flags}\")"
      ]
    }
  ]
}
