{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Svend Reasoning Model Training\n",
    "\n",
    "This notebook trains Svend reasoning models on Google Colab with A100 GPUs.\n",
    "\n",
    "**Requirements:**\n",
    "- Colab Pro+ (for A100 access)\n",
    "- Google Drive (for checkpoint persistence)\n",
    "- WandB account (optional, for experiment tracking)\n",
    "\n",
    "**Strategy:**\n",
    "1. Mount Drive for checkpoint persistence\n",
    "2. Validate infrastructure before training\n",
    "3. Train with frequent checkpoints (Colab can timeout)\n",
    "4. Evaluate before scaling up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository (or upload)\n",
    "!git clone https://github.com/YOUR_USERNAME/reasoning-lab.git\n",
    "%cd reasoning-lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch transformers datasets accelerate wandb\n",
    "!pip install -q sympy  # For math tools\n",
    "!pip install -q sentencepiece tiktoken  # For tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU and memory\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"bf16 supported: {torch.cuda.is_bf16_supported()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "CONFIG = {\n",
    "    # Model scale (start small, scale up after validation)\n",
    "    \"model_scale\": \"medium\",  # tiny, small, medium, large, xl, xxl, flagship\n",
    "    \n",
    "    # Training\n",
    "    \"experiment_name\": \"svend-colab-v1\",\n",
    "    \"num_epochs\": 2,\n",
    "    \"max_steps\": None,  # Set to limit steps (e.g., 1000 for testing)\n",
    "    \n",
    "    # Checkpointing (critical for Colab!)\n",
    "    \"save_steps\": 500,  # Save every 500 steps\n",
    "    \"checkpoint_dir\": \"/content/drive/MyDrive/svend-checkpoints\",\n",
    "    \n",
    "    # Logging\n",
    "    \"use_wandb\": True,\n",
    "    \"wandb_project\": \"svend\",\n",
    "    \n",
    "    # Resume from checkpoint (set to checkpoint path to resume)\n",
    "    \"resume_from\": None,\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WandB (optional)\n",
    "if CONFIG[\"use_wandb\"]:\n",
    "    import wandb\n",
    "    wandb.login()\n",
    "    print(\"WandB initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validate Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run infrastructure validation\n",
    "from src.pipeline import PipelineRunner, PipelineConfig\n",
    "from src.pipeline.config import ModelScale, TrainingConfig, create_quick_test_config\n",
    "\n",
    "# Quick validation\n",
    "config = create_quick_test_config()\n",
    "runner = PipelineRunner(config)\n",
    "\n",
    "if runner.validate_infrastructure():\n",
    "    print(\"\\n[SUCCESS] Infrastructure validated - ready for training!\")\n",
    "else:\n",
    "    print(\"\\n[ERROR] Infrastructure validation failed - fix issues before continuing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# You can customize which datasets to use\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Example: SlimOrca for reasoning\n",
    "try:\n",
    "    slimorca = load_dataset(\"Open-Orca/SlimOrca\", split=\"train\")\n",
    "    print(f\"SlimOrca: {len(slimorca)} examples\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load SlimOrca: {e}\")\n",
    "\n",
    "# Example: GSM8K for math\n",
    "try:\n",
    "    gsm8k = load_dataset(\"gsm8k\", \"main\", split=\"train\")\n",
    "    print(f\"GSM8K: {len(gsm8k)} examples\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load GSM8K: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Model and Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline import PipelineRunner, PipelineConfig\n",
    "from src.pipeline.config import ModelScale, TrainingConfig, DataConfig\n",
    "\n",
    "# Map string to enum\n",
    "scale_map = {\n",
    "    \"tiny\": ModelScale.TINY,\n",
    "    \"small\": ModelScale.SMALL,\n",
    "    \"medium\": ModelScale.MEDIUM,\n",
    "    \"large\": ModelScale.LARGE,\n",
    "    \"xl\": ModelScale.XL,\n",
    "    \"xxl\": ModelScale.XXL,\n",
    "    \"flagship\": ModelScale.FLAGSHIP,\n",
    "}\n",
    "\n",
    "model_scale = scale_map[CONFIG[\"model_scale\"]]\n",
    "\n",
    "# Create training config\n",
    "training = TrainingConfig(\n",
    "    experiment_name=CONFIG[\"experiment_name\"],\n",
    "    model_scale=model_scale,\n",
    "    num_epochs=CONFIG[\"num_epochs\"],\n",
    "    max_steps=CONFIG[\"max_steps\"],\n",
    "    save_steps=CONFIG[\"save_steps\"],\n",
    "    output_dir=CONFIG[\"checkpoint_dir\"],\n",
    "    use_wandb=CONFIG[\"use_wandb\"],\n",
    "    wandb_project=CONFIG[\"wandb_project\"],\n",
    "    resume_from=CONFIG[\"resume_from\"],\n",
    ")\n",
    "\n",
    "# Apply scale defaults\n",
    "training.apply_scale_defaults()\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Scale: {model_scale.value}\")\n",
    "print(f\"  Batch size: {training.batch_size}\")\n",
    "print(f\"  Grad accumulation: {training.gradient_accumulation_steps}\")\n",
    "print(f\"  Effective batch: {training.effective_batch_size}\")\n",
    "print(f\"  Learning rate: {training.learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline config\n",
    "config = PipelineConfig(\n",
    "    training=training,\n",
    "    checkpoint_dir=CONFIG[\"checkpoint_dir\"],\n",
    "    strict_validation=False,  # Don't fail on validation for now\n",
    ")\n",
    "\n",
    "# Create runner\n",
    "runner = PipelineRunner(config)\n",
    "\n",
    "print(\"Pipeline configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TRAINING\n",
    "# This cell will run for a long time!\n",
    "# Progress is saved to Google Drive\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"Checkpoints will be saved to:\", CONFIG[\"checkpoint_dir\"])\n",
    "print(\"If Colab disconnects, re-run the notebook and set resume_from to continue.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = runner.run()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Training completed!\")\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Final step: {result.final_step}\")\n",
    "print(f\"Final loss: {result.final_loss:.4f}\")\n",
    "print(f\"Training time: {result.training_time_seconds / 3600:.2f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "from src.evaluation import EvaluationSuite, quick_eval\n",
    "\n",
    "# Quick eval for validation\n",
    "print(\"Running quick evaluation...\")\n",
    "metrics = quick_eval(runner.model, runner.model.tokenizer)\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "for name, value in metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {name}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {name}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model generation\n",
    "test_prompts = [\n",
    "    \"What is 15% of 200?\",\n",
    "    \"If a train travels at 60 mph for 2.5 hours, how far does it go?\",\n",
    "    \"What is the derivative of x^2 + 3x?\",\n",
    "]\n",
    "\n",
    "print(\"Testing model generation:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    # Generate response (implementation depends on your model)\n",
    "    # response = runner.model.generate(prompt)\n",
    "    # print(f\"Response: {response}\")\n",
    "    print(\"[Generation code would go here]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model to Drive\n",
    "final_path = f\"{CONFIG['checkpoint_dir']}/{CONFIG['experiment_name']}/final\"\n",
    "\n",
    "print(f\"Saving final model to: {final_path}\")\n",
    "# runner.checkpoint_manager.save(runner.model, step=result.final_step, name=\"final\")\n",
    "\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List saved checkpoints\n",
    "import os\n",
    "\n",
    "checkpoint_base = CONFIG['checkpoint_dir']\n",
    "if os.path.exists(checkpoint_base):\n",
    "    print(\"Saved checkpoints:\")\n",
    "    for item in os.listdir(checkpoint_base):\n",
    "        item_path = os.path.join(checkpoint_base, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"  {item}\")\n",
    "else:\n",
    "    print(\"No checkpoints found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Resume Training (if needed)\n",
    "\n",
    "If Colab disconnects, run the following to resume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESUME TRAINING\n",
    "# Set the checkpoint path to resume from\n",
    "\n",
    "RESUME_FROM = \"/content/drive/MyDrive/svend-checkpoints/svend-colab-v1/step_00001000\"\n",
    "\n",
    "# Update config\n",
    "CONFIG[\"resume_from\"] = RESUME_FROM\n",
    "\n",
    "# Re-create training config with resume\n",
    "training = TrainingConfig(\n",
    "    experiment_name=CONFIG[\"experiment_name\"],\n",
    "    model_scale=model_scale,\n",
    "    num_epochs=CONFIG[\"num_epochs\"],\n",
    "    save_steps=CONFIG[\"save_steps\"],\n",
    "    output_dir=CONFIG[\"checkpoint_dir\"],\n",
    "    use_wandb=CONFIG[\"use_wandb\"],\n",
    "    wandb_project=CONFIG[\"wandb_project\"],\n",
    "    resume_from=RESUME_FROM,\n",
    ")\n",
    "training.apply_scale_defaults()\n",
    "\n",
    "config = PipelineConfig(training=training)\n",
    "runner = PipelineRunner(config)\n",
    "\n",
    "# Resume training\n",
    "result = runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "### Colab Tips:\n",
    "- A100 sessions can run up to 24 hours\n",
    "- Always checkpoint frequently (every 500 steps)\n",
    "- Mount Drive at the start to persist checkpoints\n",
    "- Use WandB to track experiments across sessions\n",
    "\n",
    "### Next Steps:\n",
    "1. After validation at current scale, increase `model_scale`\n",
    "2. Run full evaluation before production\n",
    "3. Train safety classifier separately\n",
    "4. Deploy to production infrastructure"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
